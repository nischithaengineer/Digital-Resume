{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "110bd975",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Groq API Key: Loaded\n",
            "   Key starts with: gsk_9Y07Ns...\n",
            "\n",
            "‚úÖ Eleven Labs API Key: Loaded\n",
            "   Key starts with: sk_239aa1a...\n",
            "   ‚Üí Voice features will be available\n",
            "\n",
            "‚úÖ LangChain API Key: Loaded\n",
            "   Key starts with: lsv2_pt_93...\n"
          ]
        }
      ],
      "source": [
        "# üîç Verify API Keys Setup\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "groq_key = os.getenv(\"GROQ_API_KEY\")\n",
        "elevenlabs_key = os.getenv(\"ELEVENLABS_API_KEY\")\n",
        "langchain_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "# Check Groq API Key (used for LLM)\n",
        "if groq_key:\n",
        "    print(\"‚úÖ Groq API Key: Loaded\")\n",
        "    print(f\"   Key starts with: {groq_key[:10]}...\")\n",
        "else:\n",
        "    print(\"‚ùå Groq API Key: MISSING\")\n",
        "    print(\"   ‚Üí Get it from: https://console.groq.com/keys\")\n",
        "    print(\"   ‚Üí Add to .env: GROQ_API_KEY=your_key_here\")\n",
        "print()\n",
        "\n",
        "# Check Eleven Labs API Key\n",
        "if elevenlabs_key:\n",
        "    print(\"‚úÖ Eleven Labs API Key: Loaded\")\n",
        "    print(f\"   Key starts with: {elevenlabs_key[:10]}...\")\n",
        "    print(\"   ‚Üí Voice features will be available\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Eleven Labs API Key: Not set (Optional)\")\n",
        "    print(\"   ‚Üí Voice features will be disabled\")\n",
        "    print(\"   ‚Üí Get it from: https://elevenlabs.io/\")\n",
        "    print(\"   ‚Üí Add to .env: ELEVENLABS_API_KEY=your_key_here\")\n",
        "print()\n",
        "\n",
        "if langchain_key:\n",
        "    print(\"‚úÖ LangChain API Key: Loaded\")\n",
        "    print(f\"   Key starts with: {langchain_key[:10]}...\")\n",
        "else:\n",
        "    print(\"‚ùå LangChain API Key: MISSING\")\n",
        "    print(\"   ‚Üí Get it from: https://www.langchain.com/\")\n",
        "    print(\"   ‚Üí Add to .env: LANGCHAIN_API_KEY=your_key_here\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "43291906",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nischitha/Documents/Agentic-RAG/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import (\n",
        "PyPDFLoader\n",
        ")\n",
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2defc14a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyPdfloader\n",
            "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Nischitha.D \\nBangalore | nischithaengineer123@gmail.com  | 9380665366 | \\nhttps://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \\nProfessional Summary \\nAI Engineer with six months of experience in Natural Language Processing, FastAPI and Graph Database. A \\nfive-star Python coder on HackerRank, skilled in fine-tuning large language models and Retrieval-Augmented \\nGeneration. \\nAchievement \\nMachineHack Sequence Classification Hackathon \\n‚Ä¢ Secured 13th place in the MachineHack Sequence Classification Hackathon, where I fine-tuned Google BERT for \\nmulti-class classification. \\nEducation \\nDon Bosco Institute of Technology , BE in Computer Science Oct 2020 ‚Äì June 2024 \\n‚Ä¢ CGPA: 8.1/10.0 \\n‚Ä¢ Coursework: Data Analytics, Data Science , Python \\nExperience \\nAI Engineer, Alongx Software ‚Äì Telangana, India June 2024 ‚Äì Nov 2024 \\n‚Ä¢ Built backend applications for the News360 app using FastAPI, incorporating in-memory cache to ensure \\nscalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \\npassword reset. \\n‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and newspaper3k to extract and \\nprocess real-time news articles. \\n‚Ä¢ Optimized complex relationship mapping and querying by utilizing graph databases such as Gremlin and \\nNeo4j, thus improving data retrieval efficiency. \\n‚Ä¢ Implemented the T5 Transformer model for concise text summaries. \\n \\nProjects \\nBreast Cancer Prediction \\n‚Ä¢ Analyzed breast cancer data using libraries in Python like Pandas, NumPy, and Scikit-learn. \\n‚Ä¢ Implemented Logistic Regression, Decision Trees, and Random Forest models for disease diagnosis, \\nachieving 97% accuracy with Random Forest, 96% accuracy with Logistic Regression, and 93% accuracy with \\nDecision Trees and Checked model accuracy and performance using precision, recall, and F1 Score . \\nQuestion-Answering Agent \\n‚Ä¢ Built an accurate and cost-effective question-answering agent for Insurellm Tech Company using \\nRetrieval-Augmented Generation with LangChain. \\n‚Ä¢ Added a Chroma vector store to efficiently manage the retrieval of document and conversational memory. \\n‚Ä¢ Created an interactive Gradio interface to allow for smooth and user-friendly interaction. \\nAirline AI Assistant \\n‚Ä¢ Developed an AI-powered multimodal customer support assistant for an airline using OpenAI LLM GPT-4o-mini, \\nTTS-1, and DALL-E-3. \\n‚Ä¢ Automated retrieval of ticket price and vacation-themed image generation. \\n‚Ä¢ Added text-to-speech functionality for audio responses and implemented a Gradio-based user interface.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Skills \\nTechnical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , Flask, FastAPI, \\nSeaborn,Machine Learning, Natural Language Processing, Deep Learning, Generative AI. \\nSoft Skills: Communication,Teamwork, Leadership.')]\n",
            "  Loaded 2 pages\n",
            "  Page 1 content: Skills \n",
            "Technical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , F...\n",
            "  Metadata: {'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}\n"
          ]
        }
      ],
      "source": [
        "### PypdfLoader\n",
        "print(\"PyPdfloader\")\n",
        "\n",
        "try:\n",
        "    pypdf_loader=PyPDFLoader(\"data/pdf/Nischitha.D.pdf\")\n",
        "    pypdf_docs=pypdf_loader.load()\n",
        "    print(pypdf_docs)\n",
        "    print(f\"  Loaded {len(pypdf_docs)} pages\")\n",
        "    print(f\"  Page 1 content: {pypdf_docs[1].page_content[:100]}...\")\n",
        "    print(f\"  Metadata: {pypdf_docs[1].metadata}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dad83952",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/kq/hgybz0d90wg4j52dl5bx35x80000gp/T/ipykernel_1427/873825663.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter( #splits the text into smaller chunks\n",
        "    chunk_size=1000, chunk_overlap=100\n",
        ")\n",
        "\n",
        "pdf_splits = text_splitter.split_documents(pypdf_docs)\n",
        "\n",
        "## Add alll these text to vectordb\n",
        "# HuggingFace embeddings (no API key needed); Groq is used for the LLM only\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore=FAISS.from_documents( #creates a vector database\n",
        "    documents=pdf_splits,\n",
        "    embedding=embedding\n",
        ")\n",
        "\n",
        "\n",
        "retriever=vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1cebdc38",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Nischitha.D \\nBangalore | nischithaengineer123@gmail.com  | 9380665366 | \\nhttps://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \\nProfessional Summary \\nAI Engineer with six months of experience in Natural Language Processing, FastAPI and Graph Database. A \\nfive-star Python coder on HackerRank, skilled in fine-tuning large language models and Retrieval-Augmented \\nGeneration. \\nAchievement \\nMachineHack Sequence Classification Hackathon \\n‚Ä¢ Secured 13th place in the MachineHack Sequence Classification Hackathon, where I fine-tuned Google BERT for \\nmulti-class classification. \\nEducation \\nDon Bosco Institute of Technology , BE in Computer Science Oct 2020 ‚Äì June 2024 \\n‚Ä¢ CGPA: 8.1/10.0 \\n‚Ä¢ Coursework: Data Analytics, Data Science , Python \\nExperience \\nAI Engineer, Alongx Software ‚Äì Telangana, India June 2024 ‚Äì Nov 2024 \\n‚Ä¢ Built backend applications for the News360 app using FastAPI, incorporating in-memory cache to ensure'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='scalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \\npassword reset. \\n‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and newspaper3k to extract and \\nprocess real-time news articles. \\n‚Ä¢ Optimized complex relationship mapping and querying by utilizing graph databases such as Gremlin and \\nNeo4j, thus improving data retrieval efficiency. \\n‚Ä¢ Implemented the T5 Transformer model for concise text summaries. \\n \\nProjects \\nBreast Cancer Prediction \\n‚Ä¢ Analyzed breast cancer data using libraries in Python like Pandas, NumPy, and Scikit-learn. \\n‚Ä¢ Implemented Logistic Regression, Decision Trees, and Random Forest models for disease diagnosis, \\nachieving 97% accuracy with Random Forest, 96% accuracy with Logistic Regression, and 93% accuracy with \\nDecision Trees and Checked model accuracy and performance using precision, recall, and F1 Score . \\nQuestion-Answering Agent'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Question-Answering Agent \\n‚Ä¢ Built an accurate and cost-effective question-answering agent for Insurellm Tech Company using \\nRetrieval-Augmented Generation with LangChain. \\n‚Ä¢ Added a Chroma vector store to efficiently manage the retrieval of document and conversational memory. \\n‚Ä¢ Created an interactive Gradio interface to allow for smooth and user-friendly interaction. \\nAirline AI Assistant \\n‚Ä¢ Developed an AI-powered multimodal customer support assistant for an airline using OpenAI LLM GPT-4o-mini, \\nTTS-1, and DALL-E-3. \\n‚Ä¢ Automated retrieval of ticket price and vacation-themed image generation. \\n‚Ä¢ Added text-to-speech functionality for audio responses and implemented a Gradio-based user interface.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Skills \\nTechnical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , Flask, FastAPI, \\nSeaborn,Machine Learning, Natural Language Processing, Deep Learning, Generative AI. \\nSoft Skills: Communication,Teamwork, Leadership.')]\n"
          ]
        }
      ],
      "source": [
        "print(pdf_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d2d9b907",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<langchain_community.vectorstores.faiss.FAISS object at 0x1670b7a10>\n"
          ]
        }
      ],
      "source": [
        "print(vectorstore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ae83631",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.linkedin.com/in/nischithad-aiengineer\n"
          ]
        }
      ],
      "source": [
        "# Retriever alone returns DOCUMENT CHUNKS (raw text), not an answer.\n",
        "# To get a direct answer (e.g. just the phone number), use RAG: retriever + LLM.\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "question = \"what is the linkedln profile of nischitha\"\n",
        "docs = retriever.invoke(question)\n",
        "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the question using ONLY the context below. Give a very short, direct answer (e.g. just the number or one sentence).\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\",\n",
        "    input_variables=[\"context\", \"question\"],\n",
        ")\n",
        "llm = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "answer = (prompt | llm | StrOutputParser()).invoke({\"context\": context, \"question\": question})\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "abe16547",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved chunks (raw): 4\n",
            "\n",
            "--- Chunk 1 (first 200 chars) ---\n",
            "Nischitha.D \n",
            "Bangalore | nischithaengineer123@gmail.com  | 9380665366 | \n",
            "https://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \n",
            "Professional Summary \n",
            "AI Engineer wi...\n",
            "\n",
            "--- Chunk 2 (first 200 chars) ---\n",
            "scalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \n",
            "password reset. \n",
            "‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and ne...\n"
          ]
        }
      ],
      "source": [
        "# Optional: see the raw documents the retriever returned (before the LLM turned them into an answer)\n",
        "print(\"Retrieved chunks (raw):\", len(docs))\n",
        "for i, doc in enumerate(docs[:2]):\n",
        "    print(f\"\\n--- Chunk {i+1} (first 200 chars) ---\\n{doc.page_content[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "14ab3fb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "### Retriever To Retriever Tools to integrate with the agent(LLM)\n",
        "from langchain_core.tools.retriever import create_retriever_tool\n",
        "retriever_tool_resume=create_retriever_tool(\n",
        "    retriever,\n",
        "    \"retriever_vector_db_resume\", #name of the tool\n",
        "    \"Search and run information about candidate\" #description of the tool\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9cd40fb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "tools=[retriever_tool_resume]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ea2dbe8",
      "metadata": {},
      "source": [
        "### LangGraph Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c237594f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    # The add_messages function defines how an update should be processed\n",
        "    # Default is to replace. add_messages says \"append\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fcdcd579",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm=ChatGroq(model=\"openai/gpt-oss-120b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d1014dd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def agent(state): #agent node \n",
        "    \"\"\"\n",
        "    Invokes the agent model to generate a response based on the current state. Given\n",
        "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with the agent response appended to messages\n",
        "    \"\"\"\n",
        "    print(\"---CALL AGENT---\")\n",
        "    messages = state[\"messages\"]\n",
        "    model = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "    model = model.bind_tools(tools)  # pass a list of tools\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a5ead8cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated, Literal, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "775128d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Edges\n",
        "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        str: A decision for whether the documents are relevant or not\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK RELEVANCE---\")\n",
        "\n",
        "    # Data model\n",
        "    class grade(BaseModel):\n",
        "        \"\"\"Binary score for relevance check.\"\"\"\n",
        "\n",
        "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
        "\n",
        "    # LLM\n",
        "    model = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "\n",
        "    # LLM with tool and validation\n",
        "    llm_with_tool = model.with_structured_output(grade)\n",
        "\n",
        "    # Prompt\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
        "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
        "        Here is the user question: {question} \\n\n",
        "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "\n",
        "    # Chain\n",
        "    chain = prompt | llm_with_tool\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    question = messages[0].content\n",
        "    docs = last_message.content\n",
        "\n",
        "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
        "\n",
        "    score = scored_result.binary_score\n",
        "\n",
        "    if score == \"yes\":\n",
        "        print(\"---DECISION: DOCS RELEVANT---\")\n",
        "        return \"generate\"\n",
        "\n",
        "    else:\n",
        "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
        "        print(score)\n",
        "        return \"rewrite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c0c4a177",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(state):\n",
        "    \"\"\"\n",
        "    EXECUTION PHASE: Agent EXECUTES the answer generation\n",
        " \n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "         dict: The updated message\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE (EXECUTION PHASE)---\")\n",
        "    messages = state[\"messages\"]\n",
        "    \n",
        "    # Find the most recent HumanMessage (the current question)\n",
        "    question = None\n",
        "    for msg in reversed(messages):\n",
        "        if hasattr(msg, 'type') and msg.type == 'human':\n",
        "            question = msg.content\n",
        "            break\n",
        "        elif isinstance(msg, HumanMessage):\n",
        "            question = msg.content\n",
        "            break\n",
        "    \n",
        "    # Fallback to first message if no HumanMessage found\n",
        "    if question is None:\n",
        "        question = messages[0].content if hasattr(messages[0], 'content') else str(messages[0])\n",
        "    \n",
        "    print(f\"üéØ Answering question: {question}\")\n",
        "    \n",
        "    last_message = messages[-1]\n",
        "    docs = last_message.content\n",
        "\n",
        "    # Prompt - RAG prompt template (equivalent to hub.pull(\"rlm/rag-prompt\"))\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Answer:\"\"\",\n",
        "        input_variables=[\"question\", \"context\"]\n",
        "    )\n",
        "\n",
        "    # LLM\n",
        "    llm = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "\n",
        "    # Chain\n",
        "    rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Run\n",
        "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4d3e96fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def rewrite(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "\n",
        "    msg = [\n",
        "        HumanMessage(\n",
        "            content=f\"\"\" \\n \n",
        "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
        "    Here is the initial question:\n",
        "    \\n ------- \\n\n",
        "    {question} \n",
        "    \\n ------- \\n\n",
        "    Formulate an improved question: \"\"\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Grader\n",
        "    model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
        "    response = model.invoke(msg)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "297dae82",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the nodes we will cycle between\n",
        "workflow.add_node(\"agent\", agent)  # agent\n",
        "retrieve = ToolNode(tools)\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
        "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
        "workflow.add_node(\n",
        "    \"generate\", generate\n",
        ")  # Generating a response after we know the documents are relevant\n",
        "# Call agent node to decide to retrieve or not\n",
        "workflow.add_edge(START, \"agent\")\n",
        "\n",
        "# Decide whether to retrieve\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    # Assess agent decision\n",
        "    tools_condition,\n",
        "    {\n",
        "        # Translate the condition outputs to nodes in our graph\n",
        "        \"tools\": \"retrieve\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Edges taken after the `action` node is called.\n",
        "workflow.add_conditional_edges(\n",
        "    \"retrieve\",\n",
        "    # Assess agent decision\n",
        "    grade_documents,\n",
        ")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "workflow.add_edge(\"rewrite\", \"agent\")\n",
        "\n",
        "# Compile\n",
        "graph = workflow.compile()\n",
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bb7329a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL AGENT---\n",
            "---CHECK RELEVANCE---\n",
            "---DECISION: DOCS RELEVANT---\n",
            "---GENERATE (EXECUTION PHASE)---\n",
            "üéØ Answering question: what is the email id of nischitha\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is the email id of nischitha', additional_kwargs={}, response_metadata={}, id='a86b4016-6fea-4057-9e78-daaff6a640f8'),\n",
              "  AIMessage(content='', additional_kwargs={'reasoning_content': 'The user asks: \"what is the email id of nischitha\". We need to retrieve from a resume or some data source. There\\'s a function retriever_vector_db_resume that can search a vector DB of resumes. Likely the user wants the email address of a person named Nischitha. We need to query. Use function.', 'tool_calls': [{'id': 'fc_68632b0f-d1dd-4e6f-81e6-8cd74864c181', 'function': {'arguments': '{\"query\":\"Nischitha email\"}', 'name': 'retriever_vector_db_resume'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 140, 'total_tokens': 243, 'completion_time': 0.22093576, 'prompt_time': 0.045713519, 'queue_time': 0.059011201, 'total_time': 0.266649279, 'completion_tokens_details': {'reasoning_tokens': 69}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_e10890e4b9', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--542ce174-108b-4f85-aaf1-e4fa3fe13568-0', tool_calls=[{'name': 'retriever_vector_db_resume', 'args': {'query': 'Nischitha email'}, 'id': 'fc_68632b0f-d1dd-4e6f-81e6-8cd74864c181', 'type': 'tool_call'}], usage_metadata={'input_tokens': 140, 'output_tokens': 103, 'total_tokens': 243}),\n",
              "  ToolMessage(content='Nischitha.D \\nBangalore | nischithaengineer123@gmail.com  | 9380665366 | \\nhttps://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \\nProfessional Summary \\nAI Engineer with six months of experience in Natural Language Processing, FastAPI and Graph Database. A \\nfive-star Python coder on HackerRank, skilled in fine-tuning large language models and Retrieval-Augmented \\nGeneration. \\nAchievement \\nMachineHack Sequence Classification Hackathon \\n‚Ä¢ Secured 13th place in the MachineHack Sequence Classification Hackathon, where I fine-tuned Google BERT for \\nmulti-class classification. \\nEducation \\nDon Bosco Institute of Technology , BE in Computer Science Oct 2020 ‚Äì June 2024 \\n‚Ä¢ CGPA: 8.1/10.0 \\n‚Ä¢ Coursework: Data Analytics, Data Science , Python \\nExperience \\nAI Engineer, Alongx Software ‚Äì Telangana, India June 2024 ‚Äì Nov 2024 \\n‚Ä¢ Built backend applications for the News360 app using FastAPI, incorporating in-memory cache to ensure\\n\\nscalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \\npassword reset. \\n‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and newspaper3k to extract and \\nprocess real-time news articles. \\n‚Ä¢ Optimized complex relationship mapping and querying by utilizing graph databases such as Gremlin and \\nNeo4j, thus improving data retrieval efficiency. \\n‚Ä¢ Implemented the T5 Transformer model for concise text summaries. \\n \\nProjects \\nBreast Cancer Prediction \\n‚Ä¢ Analyzed breast cancer data using libraries in Python like Pandas, NumPy, and Scikit-learn. \\n‚Ä¢ Implemented Logistic Regression, Decision Trees, and Random Forest models for disease diagnosis, \\nachieving 97% accuracy with Random Forest, 96% accuracy with Logistic Regression, and 93% accuracy with \\nDecision Trees and Checked model accuracy and performance using precision, recall, and F1 Score . \\nQuestion-Answering Agent\\n\\nQuestion-Answering Agent \\n‚Ä¢ Built an accurate and cost-effective question-answering agent for Insurellm Tech Company using \\nRetrieval-Augmented Generation with LangChain. \\n‚Ä¢ Added a Chroma vector store to efficiently manage the retrieval of document and conversational memory. \\n‚Ä¢ Created an interactive Gradio interface to allow for smooth and user-friendly interaction. \\nAirline AI Assistant \\n‚Ä¢ Developed an AI-powered multimodal customer support assistant for an airline using OpenAI LLM GPT-4o-mini, \\nTTS-1, and DALL-E-3. \\n‚Ä¢ Automated retrieval of ticket price and vacation-themed image generation. \\n‚Ä¢ Added text-to-speech functionality for audio responses and implemented a Gradio-based user interface.\\n\\nSkills \\nTechnical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , Flask, FastAPI, \\nSeaborn,Machine Learning, Natural Language Processing, Deep Learning, Generative AI. \\nSoft Skills: Communication,Teamwork, Leadership.', name='retriever_vector_db_resume', id='75998d12-71d6-4980-a3bb-41553be1bb8a', tool_call_id='fc_68632b0f-d1dd-4e6f-81e6-8cd74864c181'),\n",
              "  HumanMessage(content='Nischitha‚Äôs email address is **nischithaengineer123@gmail.com**.', additional_kwargs={}, response_metadata={}, id='6783205a-0efe-4cb9-b602-c44b5e86b33e')]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.invoke({\"messages\":\"what is the email id of nischitha\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74d6f1ea",
      "metadata": {},
      "source": [
        "### MCP Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1d5b727c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import (\n",
        "PyPDFLoader\n",
        ")\n",
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "69a4f016",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyPdfloader\n",
            "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Nischitha.D \\nBangalore | nischithaengineer123@gmail.com  | 9380665366 | \\nhttps://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \\nProfessional Summary \\nAI Engineer with six months of experience in Natural Language Processing, FastAPI and Graph Database. A \\nfive-star Python coder on HackerRank, skilled in fine-tuning large language models and Retrieval-Augmented \\nGeneration. \\nAchievement \\nMachineHack Sequence Classification Hackathon \\n‚Ä¢ Secured 13th place in the MachineHack Sequence Classification Hackathon, where I fine-tuned Google BERT for \\nmulti-class classification. \\nEducation \\nDon Bosco Institute of Technology , BE in Computer Science Oct 2020 ‚Äì June 2024 \\n‚Ä¢ CGPA: 8.1/10.0 \\n‚Ä¢ Coursework: Data Analytics, Data Science , Python \\nExperience \\nAI Engineer, Alongx Software ‚Äì Telangana, India June 2024 ‚Äì Nov 2024 \\n‚Ä¢ Built backend applications for the News360 app using FastAPI, incorporating in-memory cache to ensure \\nscalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \\npassword reset. \\n‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and newspaper3k to extract and \\nprocess real-time news articles. \\n‚Ä¢ Optimized complex relationship mapping and querying by utilizing graph databases such as Gremlin and \\nNeo4j, thus improving data retrieval efficiency. \\n‚Ä¢ Implemented the T5 Transformer model for concise text summaries. \\n \\nProjects \\nBreast Cancer Prediction \\n‚Ä¢ Analyzed breast cancer data using libraries in Python like Pandas, NumPy, and Scikit-learn. \\n‚Ä¢ Implemented Logistic Regression, Decision Trees, and Random Forest models for disease diagnosis, \\nachieving 97% accuracy with Random Forest, 96% accuracy with Logistic Regression, and 93% accuracy with \\nDecision Trees and Checked model accuracy and performance using precision, recall, and F1 Score . \\nQuestion-Answering Agent \\n‚Ä¢ Built an accurate and cost-effective question-answering agent for Insurellm Tech Company using \\nRetrieval-Augmented Generation with LangChain. \\n‚Ä¢ Added a Chroma vector store to efficiently manage the retrieval of document and conversational memory. \\n‚Ä¢ Created an interactive Gradio interface to allow for smooth and user-friendly interaction. \\nAirline AI Assistant \\n‚Ä¢ Developed an AI-powered multimodal customer support assistant for an airline using OpenAI LLM GPT-4o-mini, \\nTTS-1, and DALL-E-3. \\n‚Ä¢ Automated retrieval of ticket price and vacation-themed image generation. \\n‚Ä¢ Added text-to-speech functionality for audio responses and implemented a Gradio-based user interface.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Skills \\nTechnical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , Flask, FastAPI, \\nSeaborn,Machine Learning, Natural Language Processing, Deep Learning, Generative AI. \\nSoft Skills: Communication,Teamwork, Leadership.')]\n",
            "  Loaded 2 pages\n",
            "  Page 1 content: Skills \n",
            "Technical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , F...\n",
            "  Metadata: {'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}\n"
          ]
        }
      ],
      "source": [
        "### PypdfLoader\n",
        "print(\"PyPdfloader\")\n",
        "\n",
        "try:\n",
        "    pypdf_loader=PyPDFLoader(\"data/pdf/Nischitha.D.pdf\")\n",
        "    pypdf_docs=pypdf_loader.load()\n",
        "    print(pypdf_docs)\n",
        "    print(f\"  Loaded {len(pypdf_docs)} pages\")\n",
        "    print(f\"  Page 1 content: {pypdf_docs[1].page_content[:100]}...\")\n",
        "    print(f\"  Metadata: {pypdf_docs[1].metadata}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9da7f32f",
      "metadata": {},
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter( #splits the text into smaller chunks\n",
        "    chunk_size=1000, chunk_overlap=100\n",
        ")\n",
        "\n",
        "pdf_splits = text_splitter.split_documents(pypdf_docs)\n",
        "\n",
        "## Add alll these text to vectordb\n",
        "# HuggingFace embeddings (no API key needed); Groq is used for the LLM only\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore=FAISS.from_documents( #creates a vector database\n",
        "    documents=pdf_splits,\n",
        "    embedding=embedding\n",
        ")\n",
        "\n",
        "\n",
        "retriever=vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "93f61a9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Nischitha.D \\nBangalore | nischithaengineer123@gmail.com  | 9380665366 | \\nhttps://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \\nProfessional Summary \\nAI Engineer with six months of experience in Natural Language Processing, FastAPI and Graph Database. A \\nfive-star Python coder on HackerRank, skilled in fine-tuning large language models and Retrieval-Augmented \\nGeneration. \\nAchievement \\nMachineHack Sequence Classification Hackathon \\n‚Ä¢ Secured 13th place in the MachineHack Sequence Classification Hackathon, where I fine-tuned Google BERT for \\nmulti-class classification. \\nEducation \\nDon Bosco Institute of Technology , BE in Computer Science Oct 2020 ‚Äì June 2024 \\n‚Ä¢ CGPA: 8.1/10.0 \\n‚Ä¢ Coursework: Data Analytics, Data Science , Python \\nExperience \\nAI Engineer, Alongx Software ‚Äì Telangana, India June 2024 ‚Äì Nov 2024 \\n‚Ä¢ Built backend applications for the News360 app using FastAPI, incorporating in-memory cache to ensure'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='scalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \\npassword reset. \\n‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and newspaper3k to extract and \\nprocess real-time news articles. \\n‚Ä¢ Optimized complex relationship mapping and querying by utilizing graph databases such as Gremlin and \\nNeo4j, thus improving data retrieval efficiency. \\n‚Ä¢ Implemented the T5 Transformer model for concise text summaries. \\n \\nProjects \\nBreast Cancer Prediction \\n‚Ä¢ Analyzed breast cancer data using libraries in Python like Pandas, NumPy, and Scikit-learn. \\n‚Ä¢ Implemented Logistic Regression, Decision Trees, and Random Forest models for disease diagnosis, \\nachieving 97% accuracy with Random Forest, 96% accuracy with Logistic Regression, and 93% accuracy with \\nDecision Trees and Checked model accuracy and performance using precision, recall, and F1 Score . \\nQuestion-Answering Agent'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Question-Answering Agent \\n‚Ä¢ Built an accurate and cost-effective question-answering agent for Insurellm Tech Company using \\nRetrieval-Augmented Generation with LangChain. \\n‚Ä¢ Added a Chroma vector store to efficiently manage the retrieval of document and conversational memory. \\n‚Ä¢ Created an interactive Gradio interface to allow for smooth and user-friendly interaction. \\nAirline AI Assistant \\n‚Ä¢ Developed an AI-powered multimodal customer support assistant for an airline using OpenAI LLM GPT-4o-mini, \\nTTS-1, and DALL-E-3. \\n‚Ä¢ Automated retrieval of ticket price and vacation-themed image generation. \\n‚Ä¢ Added text-to-speech functionality for audio responses and implemented a Gradio-based user interface.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-11-21T22:58:52-08:00', 'title': \"John Doe's CV\", 'author': 'John Doe', 'moddate': '2025-11-21T22:58:52-08:00', 'source': 'data/pdf/Nischitha.D.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Skills \\nTechnical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , Flask, FastAPI, \\nSeaborn,Machine Learning, Natural Language Processing, Deep Learning, Generative AI. \\nSoft Skills: Communication,Teamwork, Leadership.')]\n"
          ]
        }
      ],
      "source": [
        "print(pdf_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8deb04de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<langchain_community.vectorstores.faiss.FAISS object at 0x17faa3250>\n"
          ]
        }
      ],
      "source": [
        "print(vectorstore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b1d1680a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tags=['FAISS', 'HuggingFaceEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x17faa3250> search_kwargs={}\n"
          ]
        }
      ],
      "source": [
        "print(retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f1a5ea8b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.linkedin.com/in/nischithad-aiengineer\n"
          ]
        }
      ],
      "source": [
        "# Retriever alone returns DOCUMENT CHUNKS (raw text), not an answer.\n",
        "# To get a direct answer (e.g. just the phone number), use RAG: retriever + LLM.\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "question = \"what is the linkedln profile of nischitha\"\n",
        "docs = retriever.invoke(question)\n",
        "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the question using ONLY the context below. Give a very short, direct answer (e.g. just the number or one sentence).\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\",\n",
        "    input_variables=[\"context\", \"question\"],\n",
        ")\n",
        "llm = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "answer = (prompt | llm | StrOutputParser()).invoke({\"context\": context, \"question\": question})\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "4bc4efb3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved chunks (raw): 4\n",
            "\n",
            "--- Chunk 1 (first 200 chars) ---\n",
            "Nischitha.D \n",
            "Bangalore | nischithaengineer123@gmail.com  | 9380665366 | \n",
            "https://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \n",
            "Professional Summary \n",
            "AI Engineer wi...\n",
            "\n",
            "--- Chunk 2 (first 200 chars) ---\n",
            "scalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \n",
            "password reset. \n",
            "‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and ne...\n"
          ]
        }
      ],
      "source": [
        "# Optional: see the raw documents the retriever returned (before the LLM turned them into an answer)\n",
        "print(\"Retrieved chunks (raw):\", len(docs))\n",
        "for i, doc in enumerate(docs[:2]):\n",
        "    print(f\"\\n--- Chunk {i+1} (first 200 chars) ---\\n{doc.page_content[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "cfaa09a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "### Retriever To Retriever Tools to integrate with the agent(LLM)\n",
        "from langchain_core.tools.retriever import create_retriever_tool\n",
        "retriever_tool_resume=create_retriever_tool(\n",
        "    retriever,\n",
        "    \"retriever_vector_db_resume\", #name of the tool\n",
        "    \"Search and run information about candidate\" #description of the tool\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ff621170",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Tool(name='retriever_vector_db_resume', description='Search and run information about candidate', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x30e75e480>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x17faa3250>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x30e75c900>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x17faa3250>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever_tool_resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a41161db",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Using Playwright MCP server\n"
          ]
        }
      ],
      "source": [
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient(\n",
        "    {\n",
        "        \"playwright\": {\n",
        "            \"transport\": \"stdio\",\n",
        "            \"command\": \"npx\",\n",
        "            \"args\": [\"@playwright/mcp@latest\"]  \n",
        "        },\n",
        "  }\n",
        "\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Using Playwright MCP server\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6fb95be8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "# Get all tools from the MCP server\n",
        "try:\n",
        "    mcp_tools = await client.get_tools()\n",
        "except Exception as e:\n",
        "    print(\"MCP ERROR:\", e)\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "458bad0a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 22 MCP tools:\n",
            "   - browser_close\n",
            "   - browser_resize\n",
            "   - browser_console_messages\n",
            "   - browser_handle_dialog\n",
            "   - browser_evaluate\n",
            "   - browser_file_upload\n",
            "   - browser_fill_form\n",
            "   - browser_install\n",
            "   - browser_press_key\n",
            "   - browser_type\n",
            "   - browser_navigate\n",
            "   - browser_navigate_back\n",
            "   - browser_network_requests\n",
            "   - browser_run_code\n",
            "   - browser_take_screenshot\n",
            "   - browser_snapshot\n",
            "   - browser_click\n",
            "   - browser_drag\n",
            "   - browser_hover\n",
            "   - browser_select_option\n",
            "   - browser_tabs\n",
            "   - browser_wait_for\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loaded {len(mcp_tools)} MCP tools:\")\n",
        "for tool in mcp_tools:\n",
        "    print(f\"   - {tool.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6ea42ed3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fixed 22 async browser tools to work with sync workflow\n",
            "üìã Total tools ready: 23\n"
          ]
        }
      ],
      "source": [
        "# Fix: Make async MCP tools work with sync LangGraph workflow\n",
        "import asyncio\n",
        "\n",
        "def make_sync_compatible(tool):\n",
        "    \"\"\"Wrap async tool to work with sync workflows\"\"\"\n",
        "    if hasattr(tool, 'coroutine') and tool.coroutine is not None:\n",
        "        original_coroutine = tool.coroutine\n",
        "        \n",
        "        def sync_wrapper(*args, **kwargs):\n",
        "            \"\"\"Run async function in sync context\"\"\"\n",
        "            try:\n",
        "                loop = asyncio.get_event_loop()\n",
        "                if loop.is_running():\n",
        "                    # If loop is already running, create a new one\n",
        "                    import nest_asyncio\n",
        "                    nest_asyncio.apply()\n",
        "            except RuntimeError:\n",
        "                loop = asyncio.new_event_loop()\n",
        "                asyncio.set_event_loop(loop)\n",
        "            \n",
        "            return loop.run_until_complete(original_coroutine(*args, **kwargs))\n",
        "        \n",
        "        # Replace the func with sync wrapper\n",
        "        tool.func = sync_wrapper\n",
        "    return tool\n",
        "\n",
        "# Make all MCP tools sync-compatible\n",
        "tools_mcp = [retriever_tool_resume] + [make_sync_compatible(t) for t in mcp_tools]\n",
        "\n",
        "print(f\"‚úÖ Fixed {len(mcp_tools)} async browser tools to work with sync workflow\")\n",
        "print(f\"üìã Total tools ready: {len(tools_mcp)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "666583a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    # The add_messages function defines how an update should be processed\n",
        "    # Default is to replace. add_messages says \"append\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a74d7397",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm=ChatGroq(model=\"openai/gpt-oss-120b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0907ce00",
      "metadata": {},
      "outputs": [],
      "source": [
        "def agent(state): #agent node \n",
        "    \"\"\"\n",
        "    Invokes the agent model to generate a response based on the current state. Given\n",
        "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with the agent response appended to messages\n",
        "    \"\"\"\n",
        "    from langchain_core.messages import SystemMessage\n",
        "    print(\"---CALL AGENT---\")\n",
        "    messages = state[\"messages\"]\n",
        "    # System prompt: use retriever + browser when needed; don't refuse\n",
        "    system_msg = SystemMessage(content=\"\"\"You are an assistant with access to a resume database and a browser (Playwright).\n",
        "1) When users ask about the candidate (e.g. email, phone, LinkedIn, skills, experience, projects), call retriever_vector_db_resume first, then answer from the retrieved context.\n",
        "2) When users ask to OPEN or VISIT a URL (e.g. 'open the LinkedIn profile', 'open GitHub profile'), you MUST: first call retriever_vector_db_resume to get the URL from the resume; then when you receive the tool result with the URL (e.g. https://www.linkedin.com/... or https://github.com/...), call browser_navigate with that URL to open the page. You have browser tools (browser_navigate, browser_tabs, etc.)‚Äîuse them when the user asks to open a link.\n",
        "3) The resume documents are the candidate's own; answering from them is allowed. Do not refuse; use the tools.\"\"\")\n",
        "    messages_with_system = [system_msg] + list(messages)\n",
        "    model = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "    model = model.bind_tools(tools_mcp)  # pass a list of tools\n",
        "    response = model.invoke(messages_with_system)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "9052b60c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated, Literal, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9a837d2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Edges\n",
        "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        str: A decision for whether the documents are relevant or not\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK RELEVANCE---\")\n",
        "\n",
        "    # Data model\n",
        "    class grade(BaseModel):\n",
        "        \"\"\"Binary score for relevance check.\"\"\"\n",
        "\n",
        "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
        "\n",
        "    # LLM\n",
        "    model = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "\n",
        "    # LLM with tool and validation\n",
        "    llm_with_tool = model.with_structured_output(grade)\n",
        "\n",
        "    # Prompt\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
        "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
        "        Here is the user question: {question} \\n\n",
        "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "\n",
        "    # Chain\n",
        "    chain = prompt | llm_with_tool\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    question = messages[0].content\n",
        "    docs = last_message.content\n",
        "\n",
        "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
        "\n",
        "    score = scored_result.binary_score\n",
        "\n",
        "    if score == \"yes\":\n",
        "        print(\"---DECISION: DOCS RELEVANT---\")\n",
        "        return \"generate\"\n",
        "\n",
        "    else:\n",
        "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
        "        print(score)\n",
        "        return \"rewrite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9625a924",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(state):\n",
        "    \"\"\"\n",
        "    EXECUTION PHASE: Agent EXECUTES the answer generation\n",
        " \n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "         dict: The updated message\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE (EXECUTION PHASE)---\")\n",
        "    messages = state[\"messages\"]\n",
        "    \n",
        "    # Find the most recent HumanMessage (the current question)\n",
        "    question = None\n",
        "    for msg in reversed(messages):\n",
        "        if hasattr(msg, 'type') and msg.type == 'human':\n",
        "            question = msg.content\n",
        "            break\n",
        "        elif isinstance(msg, HumanMessage):\n",
        "            question = msg.content\n",
        "            break\n",
        "    \n",
        "    # Fallback to first message if no HumanMessage found\n",
        "    if question is None:\n",
        "        question = messages[0].content if hasattr(messages[0], 'content') else str(messages[0])\n",
        "    \n",
        "    print(f\"üéØ Answering question: {question}\")\n",
        "    \n",
        "    last_message = messages[-1]\n",
        "    docs = last_message.content\n",
        "\n",
        "    # Prompt - RAG prompt template (equivalent to hub.pull(\"rlm/rag-prompt\"))\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Answer:\"\"\",\n",
        "        input_variables=[\"question\", \"context\"]\n",
        "    )\n",
        "\n",
        "    # LLM\n",
        "    llm = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "\n",
        "    # Chain\n",
        "    rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Run\n",
        "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "03af1909",
      "metadata": {},
      "outputs": [],
      "source": [
        "def rewrite(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "\n",
        "    msg = [\n",
        "        HumanMessage(\n",
        "            content=f\"\"\" \\n \n",
        "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
        "    Here is the initial question:\n",
        "    \\n ------- \\n\n",
        "    {question} \n",
        "    \\n ------- \\n\n",
        "    Formulate an improved question: \"\"\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Grader\n",
        "    model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
        "    response = model.invoke(msg)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "86214a1d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the nodes we will cycle between\n",
        "workflow.add_node(\"agent\", agent)  # agent\n",
        "retrieve = ToolNode(tools_mcp)\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
        "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
        "workflow.add_node(\n",
        "    \"generate\", generate\n",
        ")  # Generating a response after we know the documents are relevant\n",
        "# Call agent node to decide to retrieve or not\n",
        "workflow.add_edge(START, \"agent\")\n",
        "\n",
        "# Decide whether to retrieve\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    # Assess agent decision\n",
        "    tools_condition,\n",
        "    {\n",
        "        # Translate the condition outputs to nodes in our graph\n",
        "        \"tools\": \"retrieve\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# After retrieve: go back to agent so it can use browser_navigate or respond.\n",
        "workflow.add_edge(\"retrieve\", \"agent\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "workflow.add_edge(\"rewrite\", \"agent\")\n",
        "\n",
        "# Compile\n",
        "graph = workflow.compile()\n",
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "3093f621",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL AGENT---\n",
            "---CALL AGENT---\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is the email id of nischitha', additional_kwargs={}, response_metadata={}, id='af3a514d-4585-4863-a4f6-368fae39d144'),\n",
              "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to retrieve email from resume. Use retriever_vector_db_resume with query \"Nischitha email\".', 'tool_calls': [{'id': 'fc_90504c7f-0635-4c86-8859-d1aae333e85e', 'function': {'arguments': '{\"query\":\"Nischitha email\"}', 'name': 'retriever_vector_db_resume'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 2018, 'total_tokens': 2075, 'completion_time': 0.127174135, 'prompt_time': 0.102704228, 'queue_time': 0.044828602, 'total_time': 0.229878363, 'completion_tokens_details': {'reasoning_tokens': 23}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_d29d1d1418', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--23ca4cf6-5280-41d3-80f5-827b1bcaa55d-0', tool_calls=[{'name': 'retriever_vector_db_resume', 'args': {'query': 'Nischitha email'}, 'id': 'fc_90504c7f-0635-4c86-8859-d1aae333e85e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2018, 'output_tokens': 57, 'total_tokens': 2075}),\n",
              "  ToolMessage(content='Nischitha.D \\nBangalore | nischithaengineer123@gmail.com  | 9380665366 | \\nhttps://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \\nProfessional Summary \\nAI Engineer with six months of experience in Natural Language Processing, FastAPI and Graph Database. A \\nfive-star Python coder on HackerRank, skilled in fine-tuning large language models and Retrieval-Augmented \\nGeneration. \\nAchievement \\nMachineHack Sequence Classification Hackathon \\n‚Ä¢ Secured 13th place in the MachineHack Sequence Classification Hackathon, where I fine-tuned Google BERT for \\nmulti-class classification. \\nEducation \\nDon Bosco Institute of Technology , BE in Computer Science Oct 2020 ‚Äì June 2024 \\n‚Ä¢ CGPA: 8.1/10.0 \\n‚Ä¢ Coursework: Data Analytics, Data Science , Python \\nExperience \\nAI Engineer, Alongx Software ‚Äì Telangana, India June 2024 ‚Äì Nov 2024 \\n‚Ä¢ Built backend applications for the News360 app using FastAPI, incorporating in-memory cache to ensure\\n\\nscalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \\npassword reset. \\n‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and newspaper3k to extract and \\nprocess real-time news articles. \\n‚Ä¢ Optimized complex relationship mapping and querying by utilizing graph databases such as Gremlin and \\nNeo4j, thus improving data retrieval efficiency. \\n‚Ä¢ Implemented the T5 Transformer model for concise text summaries. \\n \\nProjects \\nBreast Cancer Prediction \\n‚Ä¢ Analyzed breast cancer data using libraries in Python like Pandas, NumPy, and Scikit-learn. \\n‚Ä¢ Implemented Logistic Regression, Decision Trees, and Random Forest models for disease diagnosis, \\nachieving 97% accuracy with Random Forest, 96% accuracy with Logistic Regression, and 93% accuracy with \\nDecision Trees and Checked model accuracy and performance using precision, recall, and F1 Score . \\nQuestion-Answering Agent\\n\\nQuestion-Answering Agent \\n‚Ä¢ Built an accurate and cost-effective question-answering agent for Insurellm Tech Company using \\nRetrieval-Augmented Generation with LangChain. \\n‚Ä¢ Added a Chroma vector store to efficiently manage the retrieval of document and conversational memory. \\n‚Ä¢ Created an interactive Gradio interface to allow for smooth and user-friendly interaction. \\nAirline AI Assistant \\n‚Ä¢ Developed an AI-powered multimodal customer support assistant for an airline using OpenAI LLM GPT-4o-mini, \\nTTS-1, and DALL-E-3. \\n‚Ä¢ Automated retrieval of ticket price and vacation-themed image generation. \\n‚Ä¢ Added text-to-speech functionality for audio responses and implemented a Gradio-based user interface.\\n\\nSkills \\nTechnical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , Flask, FastAPI, \\nSeaborn,Machine Learning, Natural Language Processing, Deep Learning, Generative AI. \\nSoft Skills: Communication,Teamwork, Leadership.', name='retriever_vector_db_resume', id='94a892e7-c522-4bb0-b292-0b876198b26d', tool_call_id='fc_90504c7f-0635-4c86-8859-d1aae333e85e'),\n",
              "  AIMessage(content='The email address listed on Nischitha‚Äôs resume is **nischithaengineer123@gmail.com**.', additional_kwargs={'reasoning_content': 'We need to answer email ID. The retrieved context shows email: nischithaengineer123@gmail.com. Provide answer.'}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 2687, 'total_tokens': 2744, 'completion_time': 0.121880857, 'prompt_time': 0.134323272, 'queue_time': 0.046223667, 'total_time': 0.256204129, 'completion_tokens_details': {'reasoning_tokens': 26}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_626f3fc5e0', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--741e5f77-1519-4d35-8357-449c0c0b651a-0', usage_metadata={'input_tokens': 2687, 'output_tokens': 57, 'total_tokens': 2744})]}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.invoke({\"messages\":\"what is the email id of nischitha\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b61d2867",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL AGENT---\n",
            "---CALL AGENT---\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is the github profile of nischitha', additional_kwargs={}, response_metadata={}, id='fce8ec11-ddab-49a0-a8a8-82b06e9e0dbd'),\n",
              "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to retrieve from resume DB the GitHub URL. Use retriever_vector_db_resume with query \"GitHub profile\".', 'tool_calls': [{'id': 'fc_2ed3a7b4-5a25-41ac-b942-009d10ddbeb7', 'function': {'arguments': '{\"query\":\"GitHub profile\"}', 'name': 'retriever_vector_db_resume'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 2018, 'total_tokens': 2077, 'completion_time': 0.127594094, 'prompt_time': 0.312368907, 'queue_time': 0.045192838, 'total_time': 0.439963001, 'prompt_tokens_details': {'cached_tokens': 1792}, 'completion_tokens_details': {'reasoning_tokens': 26}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_626f3fc5e0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b8d6fc67-b1c5-47e9-adb4-866a13f39d8d-0', tool_calls=[{'name': 'retriever_vector_db_resume', 'args': {'query': 'GitHub profile'}, 'id': 'fc_2ed3a7b4-5a25-41ac-b942-009d10ddbeb7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2018, 'output_tokens': 59, 'total_tokens': 2077}),\n",
              "  ToolMessage(content='Nischitha.D \\nBangalore | nischithaengineer123@gmail.com  | 9380665366 | \\nhttps://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \\nProfessional Summary \\nAI Engineer with six months of experience in Natural Language Processing, FastAPI and Graph Database. A \\nfive-star Python coder on HackerRank, skilled in fine-tuning large language models and Retrieval-Augmented \\nGeneration. \\nAchievement \\nMachineHack Sequence Classification Hackathon \\n‚Ä¢ Secured 13th place in the MachineHack Sequence Classification Hackathon, where I fine-tuned Google BERT for \\nmulti-class classification. \\nEducation \\nDon Bosco Institute of Technology , BE in Computer Science Oct 2020 ‚Äì June 2024 \\n‚Ä¢ CGPA: 8.1/10.0 \\n‚Ä¢ Coursework: Data Analytics, Data Science , Python \\nExperience \\nAI Engineer, Alongx Software ‚Äì Telangana, India June 2024 ‚Äì Nov 2024 \\n‚Ä¢ Built backend applications for the News360 app using FastAPI, incorporating in-memory cache to ensure\\n\\nscalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \\npassword reset. \\n‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and newspaper3k to extract and \\nprocess real-time news articles. \\n‚Ä¢ Optimized complex relationship mapping and querying by utilizing graph databases such as Gremlin and \\nNeo4j, thus improving data retrieval efficiency. \\n‚Ä¢ Implemented the T5 Transformer model for concise text summaries. \\n \\nProjects \\nBreast Cancer Prediction \\n‚Ä¢ Analyzed breast cancer data using libraries in Python like Pandas, NumPy, and Scikit-learn. \\n‚Ä¢ Implemented Logistic Regression, Decision Trees, and Random Forest models for disease diagnosis, \\nachieving 97% accuracy with Random Forest, 96% accuracy with Logistic Regression, and 93% accuracy with \\nDecision Trees and Checked model accuracy and performance using precision, recall, and F1 Score . \\nQuestion-Answering Agent\\n\\nSkills \\nTechnical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , Flask, FastAPI, \\nSeaborn,Machine Learning, Natural Language Processing, Deep Learning, Generative AI. \\nSoft Skills: Communication,Teamwork, Leadership.\\n\\nQuestion-Answering Agent \\n‚Ä¢ Built an accurate and cost-effective question-answering agent for Insurellm Tech Company using \\nRetrieval-Augmented Generation with LangChain. \\n‚Ä¢ Added a Chroma vector store to efficiently manage the retrieval of document and conversational memory. \\n‚Ä¢ Created an interactive Gradio interface to allow for smooth and user-friendly interaction. \\nAirline AI Assistant \\n‚Ä¢ Developed an AI-powered multimodal customer support assistant for an airline using OpenAI LLM GPT-4o-mini, \\nTTS-1, and DALL-E-3. \\n‚Ä¢ Automated retrieval of ticket price and vacation-themed image generation. \\n‚Ä¢ Added text-to-speech functionality for audio responses and implemented a Gradio-based user interface.', name='retriever_vector_db_resume', id='a0aa0e64-3c36-480e-a268-508bbc15b061', tool_call_id='fc_2ed3a7b4-5a25-41ac-b942-009d10ddbeb7'),\n",
              "  AIMessage(content='The GitHub profile listed on Nischitha‚Äôs resume is:\\n\\n**https://github.com/nischithaengineer**', additional_kwargs={'reasoning_content': 'We have retrieved the resume content containing the GitHub profile URL: https://github.com/nischithaengineer. The user asked: \"what is the github profile of nischitha\". So answer with that URL.'}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 2686, 'total_tokens': 2764, 'completion_time': 0.163007921, 'prompt_time': 0.057909676, 'queue_time': 0.045706027, 'total_time': 0.220917597, 'prompt_tokens_details': {'cached_tokens': 1792}, 'completion_tokens_details': {'reasoning_tokens': 45}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_d29d1d1418', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--5980a5dd-25e5-4265-87b4-4c54fdfe6737-0', usage_metadata={'input_tokens': 2686, 'output_tokens': 78, 'total_tokens': 2764})]}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.invoke({\"messages\":\"what is the github profile of nischitha\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84bc647",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---CALL AGENT---\n",
            "---CHECK RELEVANCE---\n",
            "---DECISION: DOCS RELEVANT---\n",
            "---GENERATE (EXECUTION PHASE)---\n",
            "üéØ Answering question: what is the linkeldprofile of nischitha\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is the linkeldprofile of nischitha', additional_kwargs={}, response_metadata={}, id='44cac429-3a62-4faf-8ea7-9ecf202bd118'),\n",
              "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to answer about LinkedIn profile of candidate Nischitha. Must first call retriever_vector_db_resume with appropriate query.', 'tool_calls': [{'id': 'fc_92b38d87-9142-4dea-8429-e419a97525c7', 'function': {'arguments': '{\"query\":\"Nischitha LinkedIn profile\"}', 'name': 'retriever_vector_db_resume'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 1918, 'total_tokens': 1981, 'completion_time': 0.146440579, 'prompt_time': 0.013633482, 'queue_time': 0.045087357, 'total_time': 0.160074061, 'prompt_tokens_details': {'cached_tokens': 1792}, 'completion_tokens_details': {'reasoning_tokens': 27}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_8a618bed98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--8b288fdc-9fee-4c21-b156-808bdc2a4f11-0', tool_calls=[{'name': 'retriever_vector_db_resume', 'args': {'query': 'Nischitha LinkedIn profile'}, 'id': 'fc_92b38d87-9142-4dea-8429-e419a97525c7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1918, 'output_tokens': 63, 'total_tokens': 1981}),\n",
              "  ToolMessage(content='Nischitha.D \\nBangalore | nischithaengineer123@gmail.com  | 9380665366 | \\nhttps://www.linkedin.com/in/nischithad-aiengineer  | https://github.com/nischithaengineer \\nProfessional Summary \\nAI Engineer with six months of experience in Natural Language Processing, FastAPI and Graph Database. A \\nfive-star Python coder on HackerRank, skilled in fine-tuning large language models and Retrieval-Augmented \\nGeneration. \\nAchievement \\nMachineHack Sequence Classification Hackathon \\n‚Ä¢ Secured 13th place in the MachineHack Sequence Classification Hackathon, where I fine-tuned Google BERT for \\nmulti-class classification. \\nEducation \\nDon Bosco Institute of Technology , BE in Computer Science Oct 2020 ‚Äì June 2024 \\n‚Ä¢ CGPA: 8.1/10.0 \\n‚Ä¢ Coursework: Data Analytics, Data Science , Python \\nExperience \\nAI Engineer, Alongx Software ‚Äì Telangana, India June 2024 ‚Äì Nov 2024 \\n‚Ä¢ Built backend applications for the News360 app using FastAPI, incorporating in-memory cache to ensure\\n\\nscalable API performance and Build Microsoft Azure Logic App to automate email delivery of OTPs for \\npassword reset. \\n‚Ä¢ Developed a web scraper for US news channels by using BeautifulSoup,SpaCy and newspaper3k to extract and \\nprocess real-time news articles. \\n‚Ä¢ Optimized complex relationship mapping and querying by utilizing graph databases such as Gremlin and \\nNeo4j, thus improving data retrieval efficiency. \\n‚Ä¢ Implemented the T5 Transformer model for concise text summaries. \\n \\nProjects \\nBreast Cancer Prediction \\n‚Ä¢ Analyzed breast cancer data using libraries in Python like Pandas, NumPy, and Scikit-learn. \\n‚Ä¢ Implemented Logistic Regression, Decision Trees, and Random Forest models for disease diagnosis, \\nachieving 97% accuracy with Random Forest, 96% accuracy with Logistic Regression, and 93% accuracy with \\nDecision Trees and Checked model accuracy and performance using precision, recall, and F1 Score . \\nQuestion-Answering Agent\\n\\nSkills \\nTechnical Skills: Python, Pandas, NumPy, SQL, Scikit-learn, RAG , Model Context Protocal , Flask, FastAPI, \\nSeaborn,Machine Learning, Natural Language Processing, Deep Learning, Generative AI. \\nSoft Skills: Communication,Teamwork, Leadership.\\n\\nQuestion-Answering Agent \\n‚Ä¢ Built an accurate and cost-effective question-answering agent for Insurellm Tech Company using \\nRetrieval-Augmented Generation with LangChain. \\n‚Ä¢ Added a Chroma vector store to efficiently manage the retrieval of document and conversational memory. \\n‚Ä¢ Created an interactive Gradio interface to allow for smooth and user-friendly interaction. \\nAirline AI Assistant \\n‚Ä¢ Developed an AI-powered multimodal customer support assistant for an airline using OpenAI LLM GPT-4o-mini, \\nTTS-1, and DALL-E-3. \\n‚Ä¢ Automated retrieval of ticket price and vacation-themed image generation. \\n‚Ä¢ Added text-to-speech functionality for audio responses and implemented a Gradio-based user interface.', name='retriever_vector_db_resume', id='21d6984c-ed57-4605-97cc-7f5e2c69ce50', tool_call_id='fc_92b38d87-9142-4dea-8429-e419a97525c7'),\n",
              "  HumanMessage(content='Nischitha‚Äôs LinkedIn profile is https://www.linkedin.com/in/nischithad-aiengineer.', additional_kwargs={}, response_metadata={}, id='64ecc15f-daf0-46f3-bec0-4c14f14695a2')]}"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.invoke({\"messages\":\"what is the linkeld profile of nischitha\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf656435",
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.invoke({\"messages\":\"Can you open the github profile of nischitha\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "2d60e83e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval dataset: 8 questions\n",
            "  1. What is Nischitha's email?...\n",
            "  2. What is the phone number of the candidate?...\n",
            "  3. What is Nischitha's LinkedIn profile URL?...\n",
            "  4. What is the GitHub profile of Nischitha?...\n"
          ]
        }
      ],
      "source": [
        "# Eval dataset: questions the agent should answer from resume or GitHub/project docs\n",
        "# expected_answer: key fact that must appear in the response (we check containment)\n",
        "EVAL_DATASET = [\n",
        "    # Resume (candidate) questions\n",
        "    {\"question\": \"What is Nischitha's email?\", \"expected\": \"nischithaengineer123@gmail.com\"},\n",
        "    {\"question\": \"What is the phone number of the candidate?\", \"expected\": \"9380665366\"},\n",
        "    {\"question\": \"What is Nischitha's LinkedIn profile URL?\", \"expected\": \"linkedin.com\"},\n",
        "    {\"question\": \"What is the GitHub profile of Nischitha?\", \"expected\": \"github.com/nischithaengineer\"},\n",
        "    {\"question\": \"What technical skills does Nischitha have?\", \"expected\": \"Python\"},\n",
        "    {\"question\": \"Where did Nischitha work?\", \"expected\": \"Alongx\"},\n",
        "    # Agentic Chatbot project (from GitHub retriever)\n",
        "    {\"question\": \"Tell me about the Agentic Chatbot project.\", \"expected\": \"agentic\"},\n",
        "    {\"question\": \"What are the main features of the Agentic Chatbot?\", \"expected\": \"RAG\"},\n",
        "]\n",
        "\n",
        "print(f\"Eval dataset: {len(EVAL_DATASET)} questions\")\n",
        "for i, ex in enumerate(EVAL_DATASET[:4]):\n",
        "    print(f\"  {i+1}. {ex['question'][:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6254391",
      "metadata": {},
      "source": [
        "## Agentic RAG Evaluation\n",
        "\n",
        "This section measures:\n",
        "\n",
        "- **Tool Call Accuracy**: Correct tools invoked with appropriate parameters.\n",
        "- **Tool Context Relevance**: Retrieved information is relevant to the user query.\n",
        "- **Context Precision & Recall**: Proportion of relevant chunks retrieved; whether all needed info was found.\n",
        "- **Faithfulness (Groundedness)**: Final answer is based only on retrieved docs (no hallucinations).\n",
        "- **Answer Relevance**: Final response addresses the user's original query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "0c29edd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test dataset: question, expected tool for resume Qs, and ground truth for scoring\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "\n",
        "EVAL_DATASET = [\n",
        "    {\n",
        "        \"question\": \"What is the email id of Nischitha?\",\n",
        "        \"expected_tool\": \"retriever_vector_db_resume\",\n",
        "        \"expected_answer_contains\": [\"nischithaengineer123@gmail.com\"],\n",
        "        \"query_relevant_keywords\": [\"email\", \"nischitha\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the GitHub profile of Nischitha?\",\n",
        "        \"expected_tool\": \"retriever_vector_db_resume\",\n",
        "        \"expected_answer_contains\": [\"github.com/nischithaengineer\"],\n",
        "        \"query_relevant_keywords\": [\"github\", \"profile\", \"nischitha\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the LinkedIn profile of Nischitha?\",\n",
        "        \"expected_tool\": \"retriever_vector_db_resume\",\n",
        "        \"expected_answer_contains\": [\"linkedin.com/in/nischithad-aiengineer\"],\n",
        "        \"query_relevant_keywords\": [\"linkedin\", \"profile\", \"nischitha\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are Nischitha's technical skills?\",\n",
        "        \"expected_tool\": \"retriever_vector_db_resume\",\n",
        "        \"expected_answer_contains\": [\"Python\", \"RAG\", \"FastAPI\", \"NLP\"],\n",
        "        \"query_relevant_keywords\": [\"skills\", \"technical\", \"nischitha\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Where did Nischitha work and what was her role?\",\n",
        "        \"expected_tool\": \"retriever_vector_db_resume\",\n",
        "        \"expected_answer_contains\": [\"Alongx\", \"AI Engineer\"],\n",
        "        \"query_relevant_keywords\": [\"experience\", \"work\", \"nischitha\"],\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "def run_agentic_rag(graph, question: str):\n",
        "    \"\"\"Run the compiled graph and return final state (messages).\"\"\"\n",
        "    messages = [HumanMessage(content=question)] if isinstance(question, str) else question\n",
        "    result = graph.invoke({\"messages\": messages})\n",
        "    return result.get(\"messages\", [])\n",
        "\n",
        "\n",
        "def parse_run_result(messages):\n",
        "    \"\"\"Extract query, tool calls, retrieved context, and final answer from a run.\"\"\"\n",
        "    query = \"\"\n",
        "    tool_calls_used = []  # list of {\"name\": str, \"args\": dict}\n",
        "    retrieved_context = \"\"\n",
        "    final_answer = \"\"\n",
        "\n",
        "    for m in messages:\n",
        "        if hasattr(m, \"content\"):\n",
        "            content = m.content if isinstance(m.content, str) else str(m.content)\n",
        "        else:\n",
        "            content = \"\"\n",
        "        if getattr(m, \"type\", None) == \"human\" or (hasattr(m, \"__class__\") and \"Human\" in m.__class__.__name__):\n",
        "            if content and not content.startswith(\"You are\"):\n",
        "                query = content\n",
        "        if getattr(m, \"tool_calls\", None):\n",
        "            for tc in m.tool_calls:\n",
        "                name = tc.get(\"name\") or (tc.get(\"function\") or {}).get(\"name\")\n",
        "                args = tc.get(\"args\") or {}\n",
        "                if not args and tc.get(\"function\", {}).get(\"arguments\"):\n",
        "                    import json\n",
        "                    try:\n",
        "                        args = json.loads(tc[\"function\"][\"arguments\"])\n",
        "                    except Exception:\n",
        "                        args = {}\n",
        "                tool_calls_used.append({\"name\": name, \"args\": args})\n",
        "        if getattr(m, \"name\", None) == \"retriever_vector_db_resume\" and content:\n",
        "            retrieved_context = retrieved_context + \"\\n\\n\" + content if retrieved_context else content\n",
        "\n",
        "    # Final answer = last AI (or human) message with non-empty content\n",
        "    for m in reversed(messages):\n",
        "        c = getattr(m, \"content\", \"\") or \"\"\n",
        "        if not isinstance(c, str) or len((c or \"\").strip()) < 5:\n",
        "            continue\n",
        "        is_ai = getattr(m, \"type\", None) == \"ai\" or \"AIMessage\" in type(m).__name__\n",
        "        is_human = getattr(m, \"type\", None) == \"human\" or \"HumanMessage\" in type(m).__name__\n",
        "        if is_ai:\n",
        "            final_answer = c.strip()\n",
        "            break\n",
        "    if not final_answer:\n",
        "        for m in reversed(messages):\n",
        "            c = getattr(m, \"content\", \"\") or \"\"\n",
        "            if isinstance(c, str) and c.strip() and len(c.strip()) > 5 and (\"HumanMessage\" in type(m).__name__):\n",
        "                final_answer = c.strip()\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"tool_calls\": tool_calls_used,\n",
        "        \"retrieved_context\": (retrieved_context or \"\").strip(),\n",
        "        \"final_answer\": final_answer,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "549e5a26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluators: Tool Call Accuracy, Tool Context Relevance, Context Precision/Recall, Faithfulness, Answer Relevance\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "_judge_llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)\n",
        "\n",
        "\n",
        "def eval_tool_call_accuracy(expected_tool: str, parsed: dict) -> float:\n",
        "    \"\"\"1.0 if correct tool was used with reasonable params; 0.5 if wrong params; 0.0 if wrong/missing tool.\"\"\"\n",
        "    used = parsed.get(\"tool_calls\") or []\n",
        "    if not used:\n",
        "        return 0.0\n",
        "    names = [u.get(\"name\") for u in used if u.get(\"name\")]\n",
        "    if expected_tool not in names:\n",
        "        return 0.0\n",
        "    # For retriever: check that \"query\" arg is present and non-empty\n",
        "    for u in used:\n",
        "        if u.get(\"name\") == expected_tool:\n",
        "            args = u.get(\"args\") or {}\n",
        "            if expected_tool == \"retriever_vector_db_resume\":\n",
        "                if args.get(\"query\") and len(str(args[\"query\"]).strip()) > 0:\n",
        "                    return 1.0\n",
        "                return 0.5\n",
        "            return 1.0\n",
        "    return 1.0\n",
        "\n",
        "\n",
        "def eval_tool_context_relevance(query: str, parsed: dict, judge_llm=None) -> float:\n",
        "    \"\"\"LLM judge: is the retrieved context relevant to the query? Returns 0.0 or 1.0.\"\"\"\n",
        "    ctx = (parsed.get(\"retrieved_context\") or \"\")[:3000]\n",
        "    if not ctx:\n",
        "        return 0.0\n",
        "    judge_llm = judge_llm or _judge_llm\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are an evaluator. Answer only RELEVANT or NOT_RELEVANT.\"),\n",
        "        (\"human\", \"Query: {query}\\n\\nRetrieved context (excerpt): {context}\\n\\nIs this context relevant to answering the query? Answer: RELEVANT or NOT_RELEVANT.\"),\n",
        "    ])\n",
        "    chain = prompt | judge_llm\n",
        "    out = chain.invoke({\"query\": query, \"context\": ctx})\n",
        "    text = (out.content or \"\").strip().upper()\n",
        "    return 1.0 if \"RELEVANT\" in text and \"NOT\" not in text.split()[0] else 0.0\n",
        "\n",
        "\n",
        "def eval_context_precision_recall(query: str, parsed: dict, judge_llm=None):\n",
        "    \"\"\"Precision: relevant chunks / retrieved chunks (we have one big context; treat as 1 chunk). Recall: needed info in context?\"\"\"\n",
        "    ctx = (parsed.get(\"retrieved_context\") or \"\")[:4000]\n",
        "    if not ctx:\n",
        "        return 0.0, 0.0\n",
        "    judge_llm = judge_llm or _judge_llm\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Answer with two lines: PRECISION: <0-1> RECALL: <0-1>. Consider: precision = is the retrieved text relevant; recall = does it contain all info needed to answer the query.\"),\n",
        "        (\"human\", \"Query: {query}\\n\\nRetrieved context:\\n{context}\\n\\nPRECISION (0.0 to 1.0) and RECALL (0.0 to 1.0):\"),\n",
        "    ])\n",
        "    chain = prompt | judge_llm\n",
        "    out = chain.invoke({\"query\": query, \"context\": ctx})\n",
        "    text = (out.content or \"\").strip()\n",
        "    prec, rec = 0.5, 0.5\n",
        "    for line in text.replace(\",\", \" \").split(\"\\n\"):\n",
        "        if \"PRECISION\" in line.upper():\n",
        "            try:\n",
        "                prec = float([x for x in line.split() if x.replace(\".\", \"\").isdigit()][0])\n",
        "            except (IndexError, ValueError):\n",
        "                pass\n",
        "        if \"RECALL\" in line.upper():\n",
        "            try:\n",
        "                rec = float([x for x in line.split() if x.replace(\".\", \"\").isdigit()][0])\n",
        "            except (IndexError, ValueError):\n",
        "                pass\n",
        "    prec = max(0, min(1, prec))\n",
        "    rec = max(0, min(1, rec))\n",
        "    return prec, rec\n",
        "\n",
        "\n",
        "def eval_faithfulness(parsed: dict, judge_llm=None) -> float:\n",
        "    \"\"\"Is the final answer grounded only in the retrieved context? 1.0 = faithful, 0.0 = hallucination.\"\"\"\n",
        "    ctx = (parsed.get(\"retrieved_context\") or \"\")[:3000]\n",
        "    ans = (parsed.get(\"final_answer\") or \"\").strip()\n",
        "    if not ans:\n",
        "        return 0.0\n",
        "    if not ctx:\n",
        "        return 0.0  # no context to be faithful to\n",
        "    judge_llm = judge_llm or _judge_llm\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are an evaluator. Answer only FAITHFUL or NOT_FAITHFUL.\"),\n",
        "        (\"human\", \"Retrieved context:\\n{context}\\n\\nGenerated answer:\\n{answer}\\n\\nIs the answer fully supported by the context (no hallucination)? Answer: FAITHFUL or NOT_FAITHFUL.\"),\n",
        "    ])\n",
        "    chain = prompt | judge_llm\n",
        "    out = chain.invoke({\"context\": ctx, \"answer\": ans})\n",
        "    text = (out.content or \"\").strip().upper()\n",
        "    return 1.0 if \"FAITHFUL\" in text and \"NOT\" not in text.split()[0] else 0.0\n",
        "\n",
        "\n",
        "def eval_answer_relevance(query: str, parsed: dict, judge_llm=None) -> float:\n",
        "    \"\"\"Does the final answer address the user's query? 1.0 = yes, 0.0 = no.\"\"\"\n",
        "    ans = (parsed.get(\"final_answer\") or \"\").strip()\n",
        "    if not ans:\n",
        "        return 0.0\n",
        "    judge_llm = judge_llm or _judge_llm\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are an evaluator. Answer only RELEVANT or NOT_RELEVANT.\"),\n",
        "        (\"human\", \"User query: {query}\\n\\nModel answer: {answer}\\n\\nDoes the answer address the query? Answer: RELEVANT or NOT_RELEVANT.\"),\n",
        "    ])\n",
        "    chain = prompt | judge_llm\n",
        "    out = chain.invoke({\"query\": query, \"answer\": ans})\n",
        "    text = (out.content or \"\").strip().upper()\n",
        "    return 1.0 if \"RELEVANT\" in text and \"NOT\" not in text.split()[0] else 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "8ec30676",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running: What is the email id of Nischitha?...\n",
            "---CALL AGENT---\n",
            "---CALL AGENT---\n",
            "Running: What is the GitHub profile of Nischitha?...\n",
            "---CALL AGENT---\n",
            "---CALL AGENT---\n",
            "Running: What is the LinkedIn profile of Nischitha?...\n",
            "---CALL AGENT---\n",
            "---CALL AGENT---\n",
            "Running: What are Nischitha's technical skills?...\n",
            "---CALL AGENT---\n",
            "---CALL AGENT---\n",
            "Running: Where did Nischitha work and what was her role?...\n",
            "---CALL AGENT---\n",
            "---CALL AGENT---\n",
            "Runs complete. Computing metrics...\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation: run graph on each test case, parse, then score each metric\n",
        "# Ensure 'graph' is compiled (run the MCP workflow cell or the basic workflow cell above)\n",
        "\n",
        "results = []\n",
        "for i, row in enumerate(EVAL_DATASET):\n",
        "    q = row[\"question\"]\n",
        "    print(f\"Running: {q[:50]}...\")\n",
        "    try:\n",
        "        messages = run_agentic_rag(graph, q)\n",
        "        parsed = parse_run_result(messages)\n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "        parsed = {\"query\": q, \"tool_calls\": [], \"retrieved_context\": \"\", \"final_answer\": \"\"}\n",
        "    results.append({\n",
        "        \"question\": q,\n",
        "        \"parsed\": parsed,\n",
        "        \"expected_tool\": row.get(\"expected_tool\"),\n",
        "        \"expected_answer_contains\": row.get(\"expected_answer_contains\", []),\n",
        "    })\n",
        "\n",
        "print(\"Runs complete. Computing metrics...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "9844df83",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>Tool Call Accuracy</th>\n",
              "      <th>Tool Context Relevance</th>\n",
              "      <th>Context Precision</th>\n",
              "      <th>Context Recall</th>\n",
              "      <th>Faithfulness</th>\n",
              "      <th>Answer Relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the email id of Nischitha?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the GitHub profile of Nischitha?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the LinkedIn profile of Nischitha?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are Nischitha's technical skills?</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Where did Nischitha work and what was her rol...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question  Tool Call Accuracy  \\\n",
              "0                What is the email id of Nischitha?                 1.0   \n",
              "1          What is the GitHub profile of Nischitha?                 1.0   \n",
              "2        What is the LinkedIn profile of Nischitha?                 1.0   \n",
              "3            What are Nischitha's technical skills?                 1.0   \n",
              "4  Where did Nischitha work and what was her rol...                 1.0   \n",
              "\n",
              "   Tool Context Relevance  Context Precision  Context Recall  Faithfulness  \\\n",
              "0                     1.0                  1             1.0           1.0   \n",
              "1                     1.0                  1             1.0           1.0   \n",
              "2                     1.0                  1             1.0           1.0   \n",
              "3                     1.0                  1             1.0           1.0   \n",
              "4                     1.0                  1             0.5           1.0   \n",
              "\n",
              "   Answer Relevance  \n",
              "0               1.0  \n",
              "1               1.0  \n",
              "2               1.0  \n",
              "3               1.0  \n",
              "4               1.0  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute all 5 metrics per example (LLM-as-judge calls may take a minute)\n",
        "import pandas as pd\n",
        "\n",
        "scores = []\n",
        "for r in results:\n",
        "    parsed = r[\"parsed\"]\n",
        "    q = r[\"question\"]\n",
        "    et = r.get(\"expected_tool\") or \"retriever_vector_db_resume\"\n",
        "    tool_acc = eval_tool_call_accuracy(et, parsed)\n",
        "    ctx_rel = eval_tool_context_relevance(q, parsed)\n",
        "    prec, rec = eval_context_precision_recall(q, parsed)\n",
        "    faith = eval_faithfulness(parsed)\n",
        "    ans_rel = eval_answer_relevance(q, parsed)\n",
        "    scores.append({\n",
        "        \"question\": q[:45] + \"...\" if len(q) > 45 else q,\n",
        "        \"Tool Call Accuracy\": tool_acc,\n",
        "        \"Tool Context Relevance\": ctx_rel,\n",
        "        \"Context Precision\": prec,\n",
        "        \"Context Recall\": rec,\n",
        "        \"Faithfulness\": faith,\n",
        "        \"Answer Relevance\": ans_rel,\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(scores)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "a6c68f80",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agentic RAG Evaluation ‚Äî Mean scores (0‚Äì1)\n",
            "\n",
            "Metric\n",
            "Tool Call Accuracy        1.0\n",
            "Tool Context Relevance    1.0\n",
            "Context Precision         1.0\n",
            "Context Recall            0.9\n",
            "Faithfulness              1.0\n",
            "Answer Relevance          1.0\n",
            "\n",
            "Overall (average of all metrics): 0.983\n"
          ]
        }
      ],
      "source": [
        "# Summary: mean accuracy per metric\n",
        "summary = df[[\"Tool Call Accuracy\", \"Tool Context Relevance\", \"Context Precision\", \"Context Recall\", \"Faithfulness\", \"Answer Relevance\"]].mean()\n",
        "summary.index.name = \"Metric\"\n",
        "print(\"Agentic RAG Evaluation ‚Äî Mean scores (0‚Äì1)\\n\")\n",
        "print(summary.to_string())\n",
        "print(\"\\nOverall (average of all metrics):\", round(summary.mean(), 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e9dff43",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
